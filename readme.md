
![spark_prj](https://github.com/JeeyeonKim00/Prj_TaxiAnalysis/assets/127364024/6e1ac7bc-bbbd-4aba-ad0c-51343b477e13)
### ğŸ’» ì‚¬ìš© ìŠ¤í‚¬

<aside>
<img src="/icons/checkmark_lightgray.svg" alt="/icons/checkmark_lightgray.svg" width="40px" /> `**Language` :** `Python` `SQL`

`**Tool` :** `Spark` `Airflow` `Pandas` `Matplotlib` `Seaborn` `Ubuntu` `Jupyter notebook`

</aside>

### ğŸ“‚ í”„ë¡œì íŠ¸ ê°œìš”

<aside>
<img src="/icons/checkmark_lightgray.svg" alt="/icons/checkmark_lightgray.svg" width="40px" /> **[í”„ë¡œì íŠ¸ëª…]** íƒì‹œìš”ê¸ˆ ì˜ˆì¸¡ ë° íŒŒì´í”„ë¼ì¸ êµ¬ì¶• í”„ë¡œì íŠ¸

**[ê¸°ê°„]** 2023.11

**[ì¸ì›]** ê°œì¸ í”„ë¡œì íŠ¸

**[í”„ë¡œì íŠ¸ ëª©ì ]** 

- Spark ETL íŒŒì´í”„ë¼ì¸ ì„¤ê³„: ë°ì´í„° ìˆ˜ì§‘ë¶€í„° ML ëª¨ë¸ êµ¬ì¶• ë° ì €ì¥.
- Airflowë¡œ workflow ê´€ë¦¬: airflowë¥¼ í™œìš©í•˜ì—¬ pipeline ê´€ë¦¬ ë° ìŠ¤ì¼€ì¥´ë§.
- ë‰´ìš•ì˜ yellow taxi ë°ì´í„°ë¥¼ í™œìš©í•œ íƒì‹œ ìš”ê¸ˆì˜ ë¶„ì„ ë° ì˜ˆì¸¡

**[ì§„í–‰ ê³¼ì •]**

- Spark
    - ë°ì´í„° ìˆ˜ì§‘ ë° ì ì¬: spark ì‚¬ìš©í•˜ì—¬ parquet í˜•íƒœë¡œ ìˆ˜ì§‘ ë° ì ì¬.
    - ë°ì´í„° ì „ì²˜ë¦¬: Spark SQL ì‚¬ìš©.
    - ëª¨ë¸ êµ¬ì¶•: spark MLlib ì‚¬ìš©í•˜ì—¬ íŒŒë¼ë¯¸í„° íŠœë‹ í›„ best parameterë¡œ ëª¨ë¸ í•™ìŠµ.
    - ìµœì¢… ëª¨ë¸ ì €ì¥: parquet í˜•íƒœë¡œ ì €ì¥.
- Airflow: Spark pipeline ê´€ë¦¬ ë° ìŠ¤ì¼€ì¤„ë§
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/4f75b599-cbe9-42dc-aeb3-86035d164147/3db26510-fc63-4943-a3e3-cf85c48b8e0f/Untitled.png)
    

**[í´ë” êµ¬ì¡°]**

```bash
**ubuntu**
	â”œâ”€â”€ **airflow**  
	â”‚Â Â   â””â”€â”€ dags  # airflowì˜ dagë¥¼ ì €ì¥
	â””â”€â”€ **working**
	     â””â”€â”€ **taxi_analysis2**
						â”œâ”€â”€ **spark_pipeline** # dagì—ì„œ ì‹¤í–‰í•  spark pipeline ì €ì¥
						â”‚Â Â  â”œâ”€â”€ extract_data.py
						â”‚Â Â  â”œâ”€â”€ preprocess.py
						â”‚Â Â  â”œâ”€â”€ train_model.py
						â”‚Â Â  â””â”€â”€ tune_param.py
						â””â”€â”€ **data** 
								â”œâ”€â”€ raw_data # 1ï¸âƒ£ ë‰´ìš• íƒì‹œ ë°ì´í„°(raw data) ì €ì¥
						 Â Â  â”œâ”€â”€ train_test 
						 Â Â  â”‚Â       â”œâ”€â”€ test # 2ï¸âƒ£ ë¨¸ì‹ ëŸ¬ë‹ test data ì €ì¥
						 Â Â  â”‚       â”œâ”€â”€ train # 2ï¸âƒ£ ë¨¸ì‹ ëŸ¬ë‹ train data ì €ì¥
						 Â Â  â”‚       â””â”€â”€ param # 3ï¸âƒ£ íŒŒë¼ë¯¸í„° íŠœë‹ ê²°ê³¼ ì €ì¥
                â””â”€â”€ lr_model # 4ï¸âƒ£ ìµœì¢… ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì €ì¥ 
```

</aside>

### ğŸ“ˆ EDA

<aside>
<img src="/icons/checkmark_lightgray.svg" alt="/icons/checkmark_lightgray.svg" width="40px" /> **[ë°ì´í„° ì„¤ëª…]**

ì´ 19ê°œ í”¼ì²˜ ä¸­ 6ê°œë§Œ ì‚¬ìš©.

- tpep_pickup_datetime : íƒ‘ìŠ¹ ì‹œê°„
- passenger_count: íƒ‘ìŠ¹ ìŠ¹ê° ìˆ˜
- trip_distance: ì´ë™ ê±°ë¦¬
- PULocationID: íƒ‘ìŠ¹ ìœ„ì¹˜, DOLocationID: í•˜ì°¨ ìœ„ì¹˜
- total_amount: ì´ ìš”ê¸ˆ (íšŒê·€ ë¶„ì„ì—ì„œ ëª©í‘œ ë³€ìˆ˜)
    
    ```bash
    root
     |-- VendorID: long (nullable = true)
     |-- **tpep_pickup_datetime**: timestamp (nullable = true)
     |-- tpep_dropoff_datetime: timestamp (nullable = true)
     |-- **passenger_count**: double (nullable = true)
     |-- **trip_distance**: double (nullable = true)
     |-- RatecodeID: double (nullable = true)
     |-- store_and_fwd_flag: string (nullable = true)
     |-- **PULocationID**: long (nullable = true)
     |-- **DOLocationID**: long (nullable = true)
     |-- payment_type: long (nullable = true)
     |-- fare_amount: double (nullable = true)
     |-- extra: double (nullable = true)
     |-- mta_tax: double (nullable = true)
     |-- tip_amount: double (nullable = true)
     |-- tolls_amount: double (nullable = true)
     |-- improvement_surcharge: double (nullable = true)
     |-- **total_amount**: double (nullable = true)
     |-- congestion_surcharge: double (nullable = true)
     |-- airport_fee: double (nullable = true)
    
    ```
    

[EDA1. ë°ì´í„° í™•ì¸](https://github.com/JeeyeonKim00/Toy_project/blob/dde1eb783a7c6c4967577ae70d3ee4c29ac6de81/taxi_analysis/working/taxi_analysis2/taxi_analysis.ipynb)

[EDA2. íšŒê·€ ë¶„ì„](https://github.com/JeeyeonKim00/Toy_project/blob/dde1eb783a7c6c4967577ae70d3ee4c29ac6de81/taxi_analysis/working/taxi_analysis2/taxi_fare_prediction.ipynb)

</aside>

### âš¡ Spark process

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/4f75b599-cbe9-42dc-aeb3-86035d164147/a37a3af5-28bf-49d7-9eb4-b2cf701c51dd/Untitled.png)

<aside>
<img src="/icons/checkmark_lightgray.svg" alt="/icons/checkmark_lightgray.svg" width="40px" /> 1ï¸âƒ£ **ë°ì´í„° ìˆ˜ì§‘**

- ëª¨ë“ˆëª…: **extract_data.py**
- Used library: `pyspark.sql`, `requests`
- ì£¼ìš” ê¸°ëŠ¥:
    - requests â†’ ë‰´ìš• íƒì‹œ ë°ì´í„° ì‚¬ì´íŠ¸ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
    - sparkâ†’ ìˆ˜ì§‘í•œ ë°ì´í„° ì ì¬
- ê²°ê³¼ë¬¼:  tripdata.parquet

2ï¸âƒ£ **ë°ì´í„° ì „ì²˜ë¦¬**

- ëª¨ë“ˆëª…: **preprocess.py**
- Used library: `pyspark.sql`
- ì£¼ìš” ê¸°ëŠ¥ (ì•„ë˜ì˜ â–¶ë¥¼ ëˆ„ë¥´ì‹œë©´ ìì„¸í•œ ì½”ë“œê°€ ë³´ì…ë‹ˆë‹¤.)
    - Spark SQLë¡œ ë°ì´í„° ì „ì²˜ë¦¬
        
        ```python
        taxi_df.createOrReplaceTempView('trips')
        
        # ë°ì´í„° ì „ì²˜ë¦¬
        preprocess_query = f"""
                    SELECT 
                        passenger_count,
                        PULocationID as pickup_location_id,
                        DOLocationID as dropoff_location_id,
                        trip_distance,
                        HOUR(tpep_pickup_datetime) as pickup_time,
                        DATE_FORMAT(TO_DATE(tpep_pickup_datetime), 'EEEE') AS day_of_week,
                        total_amount
                    FROM trips
                    WHERE (total_amount BETWEEN 0 AND 5000)
                    AND (trip_distance BETWEEN 0 AND 500)
                    AND passenger_count < 4
            """
        
        data_df = spark.sql(preprocess_query)
        ```
        
    - train, test data ë¶„í•  (8:2) ë° ì €ì¥
        
        ```python
        train_df, test_df = data_df.randomSplit([0.8, 0.2], seed=5)
        ```
        
- ê²°ê³¼ë¬¼: train_df, test_df

3ï¸âƒ£ **íŒŒë¼ë¯¸í„° íŠœë‹** 

- ëª¨ë“ˆëª…: **tune_param.py**
- Used library: `pyspark.sql` `pyspark.ml`
- ì£¼ìš” ê¸°ëŠ¥
    - ëª¨ë¸ë§ Pipeline ìƒì„±
        
        ```python
        stages = []
        
        cat_features = ['pickup_location_id','dropoff_location_id','day_of_week'] # ë²”ì£¼í˜• ë³€ìˆ˜
        num_features = ['passenger_count','trip_distance','pickup_time'] # ìˆ«ìí˜• ë³€ìˆ˜
        
        for col in cat_features: 
            cat_indexer = StringIndexer(inputCol= col, outputCol=col+'_idx').setHandleInvalid('keep')
            oh_encoder = OneHotEncoder(inputCols= [cat_indexer.getOutputCol()], outputCols=[col+'_oh'])
            stages += [cat_indexer, oh_encoder]
        
        for col in num_features:
            num_vec = VectorAssembler(inputCols= [col], outputCol= col+'_vec')
            num_scaler = StandardScaler(inputCol= num_vec.getOutputCol(), outputCol= col+'_scaled')
            stages += [num_vec, num_scaler]
        
        all_features = [cat+'_oh' for cat in cat_features] + [num+'_scaled' for num in num_features]
        vec_assembler = VectorAssembler(inputCols= all_features, outputCol='feature_vector')    
        stages += [vec_assembler]
        
        ## ì „ì²˜ë¦¬+ëª¨ë¸ë§ pipeline ìƒì„±
        lr = LinearRegression(maxIter=30,
                              solver='normal',
                              labelCol='total_amount',
                              featuresCol='feature_vector')
        
        cv_stages = stages + [lr]
        **cv_pipeline** = Pipeline(stages = cv_stages)
        ```
        
    - íŒŒë¼ë¯¸í„° íŠœë‹ (cross validation) ë° ìµœì  íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        
        ```python
        ## ParamGridBuilder ìƒì„±
        param_grid = ParamGridBuilder()\
                        .addGrid(lr.elasticNetParam, [0.1,0.2, 0.3, 0.4, 0.5])\
                        .addGrid(lr.regParam, [0.01, 0.02, 0.03, 0.04, 0.05])\
                        .build()
        
        ## cross validation
        **cross_val** = CrossValidator(
            estimator=cv_pipeline,
            estimatorParamMaps=param_grid,
            evaluator=RegressionEvaluator(labelCol='total_amount'),
            numFolds =5) 
        
        cv_model = cross_val.fit(toy_df)
        
        best_alpha = cv_model.bestModel.stages[-1]._java_obj.getElasticNetParam()
        best_reg_param = cv_model.bestModel.stages[-1]._java_obj.getRegParam()
        
        **hyper_param** = {'alpha': [best_alpha],
                       'reg_param': [best_reg_param]}
        
        hyper_df = pd.DataFrame(hyper_param).to_csv(f'{data_dir}/param/hyper_param_{two_month_ago.year}{two_month_ago.strftime("%m")}.csv')
        print(hyper_df)
        ```
        
- ê²°ê³¼ë¬¼: hyper_param(ìµœì  íŒŒë¼ë¯¸í„°)

**4ï¸âƒ£ ëª¨ë¸ í•™ìŠµ with best parameter** 

- ëª¨ë“ˆëª…: **train_model.py**
- Used library: `pyspark.sql` `pyspark.ml`
- ì£¼ìš” ê¸°ëŠ¥
    - ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ (parquet)
        
        ```python
        # model ìƒì„±
        lr = LinearRegression(maxIter = 30,
                              solver = 'normal',
                              labelCol = 'total_amount',
                              featuresCol='feature_vector',
                              elasticNetParam=best_alpha,
                              regParam=best_reg_param)
        
        **final_model** = lr.fit(vec_train_df)
        predictions = final_model.transform(vec_test_df)
        # predictions.cache()
        predictions.select(['trip_distance','day_of_week','total_amount','prediction']).show()
        
        # í‰ê°€
        print(f'RMSE: {final_model.summary.rootMeanSquaredError:.4f}')
        print(f'R2: {final_model.summary.r2:.4f}')
        
        model_dir = '/home/ubuntu/working/taxi_analysis2/data/lr_model'
        **final_model**.write().overwrite().save(f'{model_dir}/lr_model_{two_month_ago.year}{two_month_ago.strftime("%m")}')
        ```
        
- ê²°ê³¼ë¬¼: final_model (ìµœì¢… ëª¨ë¸ with best parameter)
</aside>

### ğŸ¢ Airflow process

<aside>
<img src="/icons/checkmark_lightgray.svg" alt="/icons/checkmark_lightgray.svg" width="40px" /> [**Airflowì˜ Dag]**

- Dagì„ í†µí•´ spark ê° ë‹¨ê³„ë¥¼ ì—°ê²°.
- ìŠ¤íŒŒí¬ íŒŒì´í”„ë¼ì¸ì˜ ìë™í™”, ìŠ¤ì¼€ì¥´ë§.
- SparkSubmitOperator ì‚¬ìš©.
- Dag
    
    ```python
    from datetime import datetime, timedelta
    from airflow import DAG
    from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator
    
    default_args ={'start_date': datetime(2021,1,1),
                    'parallelism': 10}
    
    with DAG(dag_id='taxi-price-pipeline2',
             schedule='0 0 10 * *', # ë§¤ì›” 10ì¼ ì‹¤í–‰
             default_args=default_args,
             dagrun_timeout = timedelta(minutes=60),
             tags=['spark'],
             catchup=False,
             max_active_tasks=12) as dag:
        
        **extract** = SparkSubmitOperator(
            application = '/home/ubuntu/working/taxi_analysis2/spark_pipeline/extract_data.py',
            task_id = 'extract',
            conn_id = 'spark_local'
        )
    
        **preprocess** = SparkSubmitOperator(
            application='/home/ubuntu/working/taxi_analysis2/spark_pipeline/preprocess.py',
            task_id = 'preprocess',
            conn_id = 'spark_local')
    
        **tune_hyperparameter** = SparkSubmitOperator(
          application="/home/ubuntu/working/taxi_analysis2/spark_pipeline/tune_param.py", 
          task_id="tune_hyperparameter", conn_id="spark_local")
    
        **train_model** = SparkSubmitOperator(
          application="/home/ubuntu/working/taxi_analysis2/spark_pipeline/train_model.py", 
          task_id="train_model", conn_id="spark_local")
        
        **extract >> preprocess >> tune_hyperparameter >> train_model**
    ```
    

[**ê²°ê³¼]** 

- ëª¨ë“  ë‹¨ê³„ê°€ ì„±ê³µì ìœ¼ë¡œ ì—°ê²°, ë§ˆë¬´ë¦¬ ë¨.
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/4f75b599-cbe9-42dc-aeb3-86035d164147/db635859-6715-460d-b3ed-5586421c3d85/Untitled.png)
    
</aside>

### ğŸ í”„ë¡œì íŠ¸ë¥¼ í†µí•´ ì–»ì€ ê²ƒ, ëŠë‚€ì 

<aside>
<img src="/icons/checkmark_lightgray.svg" alt="/icons/checkmark_lightgray.svg" width="40px" /> - Spark ë¥¼ í†µí•´ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì˜ ETL íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•  ìˆ˜ ìˆëŠ” ê²½í—˜ì´ì—ˆìŒ.
- Airflowì™€ Sparkë¥¼ ì—°ë™í•˜ì—¬ íŒŒì´í”„ë¼ì¸ì„ ê´€ë¦¬í•˜ê³  ìŠ¤ì¼€ì¥´ë§ê¹Œì§€ í•  ìˆ˜ ìˆëŠ” ì—­ëŸ‰ì„ ê¸°ë¥¼ ìˆ˜ ìˆì—ˆìŒ.
- ì‹¤ì‹œê°„ íƒì‹œ ë°ì´í„°ë¥¼ ë°›ì•„ì˜¤ì§€ ëª»í–ˆë‹¤ëŠ” ì ì´ ì•„ì‰¬ì›€.
- ì¶”í›„ ì‹¤ì‹œê°„ ë°ì´í„°ì™€ ìµœì¢… ëª¨ë¸ì„ ì—°ë™í•˜ì—¬ íƒì‹œ ìš”ê¸ˆì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ” ê¸°íšŒê°€ ìˆì—ˆìœ¼ë©´ ì¢‹ê² ìŒ.

</aside>
